{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccedbda7",
   "metadata": {},
   "source": [
    "# Grid search with sklearn\n",
    "\n",
    "\n",
    "Grid Search is a brute force method to find the best hyperparameters for a specific dataset and model. It is possible to combine it with cross-validation and pipelines to automate this task. Here you have a visual representation of this task, a heatmap with all the accuracy values for several hyperparameters combinations.\n",
    "\n",
    "<img src=\"https://mlr.mlr-org.com/articles/tutorial/hyperpar_tuning_effects_files/figure-html/unnamed-chunk-11-1.png\" alt=\"Grid Search\" style=\"width: 500px;\"/>\n",
    "\n",
    "SKlearn provides a complete toolbox for that. In this notebook, we concentrated on the GridSearchCV function.\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "For this exercise we are going to use a data file called **mortgages**. This file contains information about clients that wish to buy a house, and whereas they were given the mortgage or not. The aim of this exercise is to prepare the dataset for training different tree models.\n",
    "\n",
    "In the following link, you can download a it:\n",
    "\n",
    "https://github.com/jnin/information-systems/raw/main/data/mortgages.csv\n",
    "\n",
    "\n",
    "The data is presented in a csv format. The dataset contains the following attributes:\n",
    "\n",
    "\n",
    "|Variable\t|Definition\t|Key|\n",
    "|---------|------------|-----------------|\n",
    "|income\t|\tFamily income| Integer|\n",
    "|regular_bills\t|general expenses\t|Integer|\n",
    "|car_bills\t|car related expenses|Integer\t|\n",
    "|other_bills\t|extraordinary expenses |Integer\t|\n",
    "|savings\t| Down payment amount| Integer\t|\n",
    "|house_price\t|house value  |Integer\t|\n",
    "|marital_status\t|marital status\t|divorced, married or single|\n",
    "|number_of_children\t|number of children\t|0,1,3,4|\n",
    "|mortgage\t| credit given\t|0 = No, 1 = Yes|\n",
    "\n",
    "<div class=\"alert alert-info\"><b>Exercise 1.1</b> \n",
    "\n",
    "Create a dataframe called ```df``` that contains the provided data. Extract the features matrix and target array from ```df``` and store them in two new variables called ```X```and ```y```, respectively. \n",
    "\n",
    "Output label distribution to check how unbalanced they are. \n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Use the last column `mortgage` as the target variable.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d282fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3315057  0.08022103 0.03531816]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This Lasso instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m lasso \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLasso()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(cross_val_score(lasso, X, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/sklearn/base.py:848\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 848\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/sklearn/linear_model/_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1116\u001b[0m, in \u001b[0;36mElasticNet._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decision function of the linear model.\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;124;03m        The predicted decision function.\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/sklearn/utils/validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This Lasso instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data[:150]\n",
    "y = diabetes.target[:150]\n",
    "lasso = linear_model.Lasso()\n",
    "print(cross_val_score(lasso, X, y, cv=3))\n",
    "lasso.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ed507",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f46c5a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1.2</b> \n",
    "    \n",
    "Write the code to normalize the data using a ```StandardScaler``` and train a ```LogisticRegression```. Then, check the score of your model. Remember to split your data into train and test datasets.\n",
    "\n",
    "We will use this model as a baseline for the remaining exercises.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "To save time, we have provided code for a possible column transformer that imputes missing values in the `'marital_status'` and `'regular_bills'` columns, along with an encoder for the `'marital_status'` column.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "imputer_cat = ('imputer_cat', SimpleImputer(strategy = 'most_frequent'))\n",
    "ohe = ('encoder', OneHotEncoder(sparse_output=False))\n",
    "\n",
    "marital_status_pipe = Pipeline([imputer_cat, ohe])\n",
    " \n",
    "transformer = ColumnTransformer([('marital_status_transformations', marital_status_pipe,['marital_status']),\n",
    "                                 ('imputer_num', SimpleImputer(strategy = 'median'), ['regular_bills'])], \n",
    "                                 remainder = 'passthrough')\n",
    "\n",
    "\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08be3d2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1.3</b> \n",
    "    \n",
    "Write code to print the `classification_report` for the previous pipeline, then examine the output. Do you notice any issues related to the dataset's unbalance?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21729c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782551c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1.4</b> \n",
    "    \n",
    "Write code to create a second `Pipeline`, this time setting the `class_weight='balanced'` parameter in `LogisticRegression`. Print the `classification_report` for this model and compare it with the previous one. Did setting the class weight address the unbalance-related issues?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd45e5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1.5</b> \n",
    "\n",
    "\n",
    "To further improve the recall metric performance of our logistic regression model, we need to try different hyperparameters. To do this, we can use  ```GridSearchCV``` sklearn function. Write the code to find the best hyperparameters for our morgage dataset using the recall as the main scoring metric.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "To save time, weâ€™ve provided a sample `param_grid` dictionary with a predefined search space. Before using it, make sure to adjust the dictionary keys to match your pipeline. Additionally, refer to the scikit-learn documentation to understand the different hyperparameters and make any necessary adjustments.\n",
    "\n",
    "The execution time of this exercise may vary based on your laptop's performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'transformer__imputer_num__strategy' : ['median','mean','most_frequent'],\n",
    "              'lg__tol' : [0.1, 0.01, 0.001, 0.0001],\n",
    "              'lg__class_weight' : ['balanced', None],\n",
    "              'lg__C' : [0.8, 1.0, 1.2],\n",
    "              'lg__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'lg__max_iter' : [100, 200, 300]\n",
    "}\n",
    "\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a7344",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1.6</b> \n",
    "    \n",
    "Write code to print the best hyperparameters found. Then, verify that the best estimator is fitted with these hyperparameters. Finally, print the generalization `classification_report` for the best estimator and check if we have achieved a better recall metric.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3964d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04966d55",
   "metadata": {},
   "source": [
    "# Predict FIFA 2018 Man of the Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b6443",
   "metadata": {},
   "source": [
    "Through the following link, you can download a dataset containing information on football players' performance in the 2018 FIFA World Cup, which can be used to predict who will be selected as the most valuable player of each match.\n",
    "\n",
    "\n",
    "https://raw.githubusercontent.com/jnin/information-systems/main/data/FIFA_2018_stats.csv\n",
    "\n",
    "\n",
    "The data are presented in a csv format. The dataset contains the following attributes:\n",
    "\n",
    "* Goal Scored\n",
    "* Ball Possession %\n",
    "* Attempts\n",
    "* On-Target\n",
    "* Off-Target\n",
    "* Blocked\n",
    "* Corners\n",
    "* Offsides\n",
    "* Free Kicks\n",
    "* Saves\n",
    "* Pass Accuracy %\n",
    "* Passes\n",
    "* Distance Covered (Kms)\n",
    "* Fouls Committed\n",
    "* Yellow Card\n",
    "* Yellow & Red\n",
    "* Red\n",
    "* Goals in PSO\n",
    "* **Man of the Match**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><b>Exercise 1</b> \n",
    "\n",
    "Create a dataframe called ```df``` that contains the provided data, extract the features matrix and target array from ```df``` and store them in two new variables called ```X```and ```y```, respectively.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "The target attribute in this dataset is the ```Man of the Match```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a672a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79141f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 2</b> \n",
    "    \n",
    "Write code to normalize the data using a `MinMaxScaler` and train a `LogisticRegression` model. To do this, create a pipeline containing both steps. After fitting the model, evaluate its performance by checking the `score` of the trained model. Remember to perform the train test split before using the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ec3e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 3</b> \n",
    "\n",
    "Write code to predict both the hard and soft labels for the test data using the previously trained pipeline. Store them in two variables named ```y_pred``` and ```y_pred_proba```. 'Hard labels' refer to the predicted class labels, while 'soft labels' represent the corresponding prediction probabilities.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "592c6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f392756",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 4</b> \n",
    "\n",
    "Write code to calculate the `recall_score` for the test data, using the `binary`, `macro`, `micro`, and `weighted` averaging methods. Analyze and explain the differences between these values.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a40925",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 5</b> \n",
    "\n",
    "Write code to calculate the `precision_score` for the test data, using the `binary`, `macro`, `micro`, and `weighted` averaging methods. Analyze and explain the differences between these values.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5909da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68857e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 6</b> \n",
    "\n",
    "Write code to calculate the `f1_score` for the test data, using the `binary`, `macro`, `micro`, and `weighted` averaging methods. Analyze and explain the differences between these values.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0d0cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 7</b> \n",
    "\n",
    "Write code to plot the `roc_curve` for the test data, and store the false positive rates, true positive rates, and thresholds in the variables `fpr`, `tpr`, and `thresholds`, respectively. Afterward, run the provided cell to generate the ROC curve plot.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf7248",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 8</b> \n",
    "\n",
    "Write code to calculate the `roc_auc_score` for the test data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b19a6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "**Bonus track:**\n",
    "\n",
    "In this [link](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py), you will find a comprehensive notebook for practicing AUC and ROC metrics in multiclass classification problems. Below are three pre-prepared datasets for your use:\n",
    "    \n",
    "* https://raw.githubusercontent.com/jnin/information-systems/refs/heads/main/data/Raisin_Dataset.csv (three-labeled dataset)\n",
    "* https://raw.githubusercontent.com/jnin/information-systems/refs/heads/main/data/brexit.csv (three-labeled dataset)\n",
    "* https://raw.githubusercontent.com/jnin/information-systems/refs/heads/main/data/winequality-white.csv (Many labels)\n",
    "    \n",
    "The target variable in all cases is located in the last column.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
